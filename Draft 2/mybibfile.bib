@book{test, 
  added-at = {2016-05-28T11:32:58.000+0200},
  address = {Z\"{u}rich},
  biburl = {https://www.bibsonomy.org/bibtex/282fd129e6a7cba0ad54c64e0a34f795c/flint63},
  description = {12. Auflage 2012},
  edition = 13,
  editor = {Haberfellner, Reinhard and de Weck, Olivier L. and Fricke, Ernst and V\"{o}ssner, Siegfried},
  file = {OFV Product page:http\://www.ofv.ch/?pagename=sdt&id=14546:URL;Amazon Search inside:http\://www.amazon.de/gp/reader/328004068X/:URL},
  groups = {public},
  interhash = {639c6250b5b1da815ed0ad46b1f2cc78},
  intrahash = {82fd129e6a7cba0ad54c64e0a34f795c},
  isbn = {978-3-280-04068-3                    },
  keywords = {01624 101 book shelf system engineering development design process project management intro},
  publisher = {Orell F\"{u}ssli},
  timestamp = {2017-07-13T17:34:22.000+0200},
  title = {Systems Engineering: Grundlagen und Anwendung},
  username = {flint63},
  year = 2015
}

@book{Syshandb2000,
	added-at = {2008-07-29T11:08:07.000+0200},
	biburl = {https://www.bibsonomy.org/bibtex/2123b885948042dc7296ecfca7b4e5bfc/stephan_dlr},
	editor = {on Systems Engineering, International Council},
	interhash = {8f42b262d39587cba43eaa13428def7c},
	intrahash = {123b885948042dc7296ecfca7b4e5bfc},
	keywords = {INCOSE Systems-Engineering},
	timestamp = {2008-07-29T11:08:07.000+0200},
	title = {INCOSE Systems Engineering Handbook},
	volume = {2.0},
	year = 2000
}

@article{kingsford2008decision,
  title={What are decision trees?},
  author={Kingsford, Carl and Salzberg, Steven L},
  journal={Nature biotechnology},
  volume={26},
  number={9},
  pages={1011--1013},
  year={2008},
  publisher={Nature Publishing Group US New York}
  Note= {gives an overview to decision trees and its use in science. The authors describe decision trees' basic concepts and highlight their capacity to tackle difficult categorization tasks by recursively splitting data based on input features. They explore the benefits and drawbacks of decision trees.}
}

@article{kotsiantis2013decision,
  title={Decision trees: a recent overview},
  author={Kotsiantis, Sotiris B},
  journal={Artificial Intelligence Review},
  volume={39},
  pages={261--283},
  year={2013},
  publisher={Springer}
  Note= {It provides a thorough examination of decision tree algorithms and their applications in artificial intelligence. The author goes through basic ideas, several types of decision trees, building methods, assessment measures, and pruning approaches. The study also discusses the advantages and disadvantages of decision trees, as well as their integration with other machine learning approaches.}
}

@article{rokach2005decision,
  title={Decision trees},
  author={Rokach, Lior and Maimon, Oded},
  journal={Data mining and knowledge discovery handbook},
  pages={165--192},
  year={2005},
  publisher={Springer}
  Note = {It gives a thorough understanding of decision trees, a common machine learning technique. The writers go over the fundamental ideas, design, and assessment of decision trees, as well as numerous splitting criteria and pruning approaches. They also go into complex issues including cluster approaches, missing value management, and decision tree representation. }
}



@article{loh2011classification,
  title={Classification and regression trees},
  author={Loh, Wei-Yin},
  journal={Wiley interdisciplinary reviews: data mining and knowledge discovery},
  volume={1},
  number={1},
  pages={14--23},
  year={2011},
  publisher={Wiley Online Library}
  Note= {The author discusses the construction of decision trees for both classification and regression tasks, including the splitting criteria and pruning techniques. Author also explores the interpretation and visualization of decision trees, as well as their applications in various domains.} 
}



@article{podgorelec2002decision,
  title={Decision trees: an overview and their use in medicine},
  author={Podgorelec, Vili and Kokol, Peter and Stiglic, Bruno and Rozman, Ivan},
  journal={Journal of medical systems},
  volume={26},
  pages={445--463},
  year={2002},
  publisher={Springer}
  Note= { This article provides a thorough introduction of decision trees and their applications in medicine. The writers go through the fundamental principles and design of decision trees, as well as attribute selection measures and tree pruning procedures. They also study the benefits and drawbacks of decision trees in medical decision-making, providing instances of their use in diverse medical areas.
  }
}

@article{loh2011classification,
  title={Classification and regression trees},
  author={Loh, Wei-Yin},
  journal={Wiley interdisciplinary reviews: data mining and knowledge discovery},
  volume={1},
  number={1},
  pages={14--23},
  year={2011},
  publisher={Wiley Online Library}
}

@article{timofeev2004classification,
  title={Classification and regression trees (CART) theory and applications},
  author={Timofeev, Roman},
  journal={Humboldt University, Berlin},
  volume={54},
  year={2004}
  Note= {This paper examines the basic ideas, algorithmic details, and mathematical foundations of CART in detail. It goes over how to build decision trees for classification and regression problems, as well as practical issues like dealing with missing values, variable selection, and model interpretation.}
}

@misc{brownlee2018implement,
  title={How to implement the decision tree algorithm from scratch in python},
  author={Brownlee, Jason},
  year={2018}
  Note = {It covers the decision tree algorithm's essential principles and implementation details, making it a helpful resource for understanding the inner workings of decision trees approach.}
}

@article{biehler2021introducing,
  title={Introducing students to machine learning with decision trees using CODAP and Jupyter Notebooks},
  author={Biehler, Rolf and Fleischer, Yannik},
  journal={Teaching Statistics},
  volume={43},
  pages={S133--S142},
  year={2021},
  publisher={Wiley Online Library}
  Note= { It provides a realistic strategy for teaching machine learning topics to students. It looks at how CODAP and Jupyter Notebooks may be used to create an interactive learning environment where students can develop and analyze decision tree models using real-world datasets.}
}

@misc{towardsdatascienceDecisionTrees,
author = {Shailey Dash},
title = {{D}ecision {T}rees {E}xplained — {E}ntropy, {I}nformation {G}ain, {G}ini {I}ndex, {C}{C}{P} {P}runing.. --- towardsdatascience.com},
howpublished = {\url{https://towardsdatascience.com/decision-trees-explained-entropy-information-gain-gini-index-ccp-pruning-4d78070db36c}},
year = {},
Note = {[Accessed 27-May-2023]
gives a thorough overview of fundamental ideas linked to decision trees. It goes into the mathematical foundations and practical aspects of developing decision tree models, including entropy, information gain, the Gini index, and cost-complexity pruning. The essay is a great resource for learning about the many components and approaches involved in decision tree creation and optimization.
},
}